name: Billion Rows Challenge

on:
  pull_request:
    branches: [main, master]
    paths:
      - 'examples/real-world/billion_rows/**'
      - 'pool/**'
      - 'internal/scheduler/**'
      - '.github/workflows/billion-rows-demo.yml'
  push:
    branches: [main, master]
    paths:
      - 'examples/real-world/billion_rows/**'
      - 'pool/**'
      - 'internal/scheduler/**'
  workflow_dispatch:
    inputs:
      rows:
        description: 'Number of rows to process'
        required: false
        default: '10000000'
      chunk_size:
        description: 'Rows per task chunk'
        required: false
        default: '500'

permissions:
  contents: read
  pull-requests: write

jobs:
  billion-rows-challenge:
    name: Chunk Size ${{ matrix.chunk_size }}
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        chunk_size: [100, 500, 1000, 5000, 10000]

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: "1.24"
          cache: true
          cache-dependency-path: examples/real-world/billion_rows/go.sum

      - name: Download dependencies
        working-directory: examples/real-world/billion_rows
        run: go mod download

      - name: Run billion rows challenge
        working-directory: examples/real-world/billion_rows
        run: |
          echo "=========================================="
          echo "Testing Chunk Size: ${{ matrix.chunk_size }} rows"
          echo "Dataset: 10,000,000 temperature readings"
          echo "=========================================="
          echo ""
          go run . -rows=10000000 -chunk=${{ matrix.chunk_size }} -ci

      - name: Save results
        run: |
          mkdir -p results
          echo "Chunk Size: ${{ matrix.chunk_size }}" > results/chunk-${{ matrix.chunk_size }}.txt
          echo "Completed at: $(date)" >> results/chunk-${{ matrix.chunk_size }}.txt

      - name: Upload results
        uses: actions/upload-artifact@v5
        with:
          name: results-chunk-${{ matrix.chunk_size }}
          path: results/
          retention-days: 7

  comparison-summary:
    name: Generate Comparison Summary
    needs: billion-rows-challenge
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Download all results
        uses: actions/download-artifact@v7
        with:
          path: all-results

      - name: Create comparison summary
        run: |
          echo "# ðŸ“Š Billion Rows Challenge - Chunk Size Comparison" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Dataset:** 10,000,000 temperature readings" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Tested Chunk Sizes:** [100, 500, 1000, 5000, 10000]" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          for chunk in 100 500 1000 5000 10000; do
            if [ -d "all-results/results-chunk-${chunk}" ]; then
              echo "âœ… **Chunk size ${chunk}**: Success - [View Job Logs](#)" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ **Chunk size ${chunk}**: Failed" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ’¡ **Tip:** View individual job logs above for detailed performance metrics and strategy comparisons." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¥ **Download artifacts** to see timestamped results for each chunk size." >> $GITHUB_STEP_SUMMARY
